{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAY 1 - MONDAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching strategy from getting html data in soup form and pickling it to making a Mongo DB in docker to hold all the data (duh).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potentially switching to Postgres database vs Mongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pushing forward with Mongo DB for now - not worth it to figure out POSTGRES with Mongo DB already working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried to work with Scrapy, but did not get too far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAY 2 - TUESDAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decided to use Beautiful Soup Loops to get data from AZ Lyrics - website architecture allows 2 loops to get everything really.  Will save Scrapy for another day (will need for more complex websites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully made a workflow to scrape AZ Lyrics - so far got all artists that start with \"L\"(705) or a number(89).  Did trials regarding timing out - 5s timer still doesnt work.  VPN work around for now - averages 125 per pull.  Need to narrow down scope or find a timer that works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to work on Spoify API - going to use \"Spotipy\" package to help.  Will go to Linh for more help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAY 3 - WEDNESDAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31s overnight timer works well, otherwise ~100 pulls before the door closes.\n",
    "\n",
    "Used Ranker.com to identify top artists per region, got 25 per each (West Coast, East Coast, South, Midwest)\n",
    "\n",
    "Got google trend data for relevancy of each artist over time.\n",
    "\n",
    "Got Spotify data for # of followers (portion of the popularity metric needed to be applied to GTrend Data)\n",
    "\n",
    "Started pulling lyrical data on top artists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAY 4 - THURSDAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulled all song data on top 3 artists per region (NEED TOTALS)\n",
    "\n",
    "Working on Presentation\n",
    "\n",
    "Direction of \"Why Midwest is doing better than the rest\"\n",
    "\n",
    "Maybe do why are they all so narcissistic?  Or if you say more bad words you are more popular.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
